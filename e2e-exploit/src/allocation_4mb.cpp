#include "allocation_4mb.hpp"
// #include "rubench.hpp"

#include <cstdio>
#include <cstdlib>
#include <ctime>
#include <sys/mman.h>
#include <unistd.h>
#include <cstdint>

#define ZONE_RESERVE 0xc0000000UL

static void* last_page_begin(void* base, size_t len, size_t page_sz) {
    uintptr_t last_byte = (uintptr_t)base + len - 1;
    return (void*)(last_byte & ~(uintptr_t)(page_sz - 1));
}

/* Return a page-aligned, contiguous region of exactly block_size bytes,
 * chosen uniformly at random from the last 10 % of a much larger “drain”
 * area that has been populated with physical pages.                    */
void* acquire_contiguous_page_block2(size_t block_size) {
    /* 1. Discover the real page size ------------------------------------- */
    const size_t page_sz = (size_t)sysconf(_SC_PAGESIZE);
    if(!page_sz) {
        perror("sysconf(_SC_PAGESIZE)");
        exit(EXIT_FAILURE);
    }

    /* 2. Validate caller’s request --------------------------------------- */
    if(block_size == 0 || block_size % page_sz) {
        fprintf(stderr, "block_size (%zu) must be a positive multiple of system page size (%zu)\n",
                block_size, page_sz);
        exit(EXIT_FAILURE);
    }

    /* 3. Drain almost all free pages ------------------------------------- */
    const size_t avail_pages = (size_t)sysconf(_SC_AVPHYS_PAGES);
    size_t drain_size        = page_sz * avail_pages - ZONE_RESERVE;

    void* drain = mmap(NULL, drain_size, PROT_READ | PROT_WRITE,
                       MAP_PRIVATE | MAP_ANONYMOUS | MAP_POPULATE, -1, 0);
    if(drain == MAP_FAILED) {
        perror("mmap(drain)");
        exit(EXIT_FAILURE);
    }

    /* -------------------------------------------------------------------- *
     *            ┌────────────────── drain_size ───────────────────┐
     *   drain -->│................................................│<- drain+drain_size
     *            │                last 10 % window                │
     *            └── window_start --→                  ←-- window_end
     *
     * Choose ‘offset’ ∈ [window_start … window_end] (inclusive)
     * in *page_sz* steps so the start is page-aligned.  Then          *
     * keep [offset … offset+block_size) and unmap everything else.    *
     * -------------------------------------------------------------------- */

    /* 4. Define the window [window_start … window_end] ------------------- */
    size_t window_start = (size_t)(drain_size * 0.9); /* first byte of last 10 % */
    if(window_start + block_size > drain_size) /* guard tiny drain mappings */
        window_start = drain_size - block_size;

    /* Round start *up* and end *down* to the next/prev page boundary       */
    window_start      = (window_start + page_sz - 1) & ~(page_sz - 1);
    size_t window_end = (drain_size - block_size) & ~(page_sz - 1);

    /* If the mapping is very small, the window may collapse to one slot    */
    if(window_start > window_end)
        window_start = window_end;

    /* 5. Uniformly pick one page-aligned slot inside the window ----------- */
    size_t num_slots = (window_end - window_start) / page_sz + 1;

    static int seeded;
    if(!seeded) {
        srand((unsigned)time(NULL));
        seeded = 1;
    }
    size_t slot = (size_t)(rand() % num_slots);

    size_t offset     = window_start + slot * page_sz;
    void* first_page  = (char*)drain + offset;
    void* after_block = (char*)first_page + block_size;

    /* 6. Trim everything outside the chosen block ------------------------ */
    if(offset > 0)
        munmap(drain, offset); /* leading gap   */
    if((char*)drain + drain_size > (char*)after_block)
        munmap(after_block, (char*)drain + drain_size - (char*)after_block); /* trailing gap  */

    return first_page; /* done!         */
}

/**
 * Drain almost all free RAM, then return the first byte of a
 * `block_size`-long page-aligned segment that ends on the last page
 * we still own.  Everything outside that segment is immediately unmapped,
 * so the caller receives the smallest possible VMA.
 *
 * @param block_size  desired length in bytes (MUST be a multiple
 *                    of the system page size, typically 4096).
 * @return            pointer to the beginning of the kept block,
 *                    or never returns on fatal error.
 */
void* acquire_contiguous_page_block(size_t block_size) {
    /* 1.  Discover the system’s real page size at run time */
    const auto page_sz = (size_t)sysconf(_SC_PAGESIZE);
    if(page_sz == 0) {
        perror("sysconf(_SC_PAGESIZE)");
        exit(EXIT_FAILURE);
    }

    /* 2.  Sanity-check the caller’s request */
    if(block_size == 0 || block_size % page_sz) {
        fprintf(stderr, "block_size (%zu) must be a positive multiple of system page size (%zu)\n",
                block_size, page_sz);
        exit(EXIT_FAILURE);
    }

    /* 3.  Drain almost all free pages so the buddy allocator has
     *     to split large blocks and hand us contiguous memory      */
    const size_t avail_pages = (size_t)sysconf(_SC_AVPHYS_PAGES);
    size_t drain_size        = page_sz * avail_pages - ZONE_RESERVE;

    void* drain = mmap(nullptr, drain_size, PROT_READ | PROT_WRITE,
                       MAP_PRIVATE | MAP_ANONYMOUS | MAP_POPULATE, -1, 0);
    if(drain == MAP_FAILED) {
        perror("mmap(drain)");
        exit(EXIT_FAILURE);
    }

    /* 4.  Find the *first byte* of the last page in that mapping */
    void* last_page = last_page_begin(drain, drain_size, page_sz);

    /* 5.  Rewind exactly ‘block_size – page_sz’ bytes so that
     *     the block we keep ends at last_page and is block_size long */
    void* first_page = (void*)((uintptr_t)last_page - (block_size - page_sz));

    /* 6.  Trim everything we no longer need.
     *     Leading hole:  [drain .. first_page)
     *     Trailing hole: (first_page+block_size .. drain+drain_size)  */
    uintptr_t drain_u   = (uintptr_t)drain;
    uintptr_t want_u    = (uintptr_t)first_page;
    uintptr_t want_end  = want_u + block_size;
    uintptr_t drain_end = drain_u + drain_size;

    if(want_u > drain_u) {
        munmap((void*)drain_u, want_u - drain_u); /* leading gap */
    }
    if(drain_end > want_end) {
        munmap((void*)want_end, drain_end - want_end); /* trailing gap */
    }

    return first_page; /* contiguous block of exactly block_size bytes */
}
