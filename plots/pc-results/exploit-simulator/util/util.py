import os
import re
from collections import defaultdict

DDR5_DIMMS = {
    'DIMM_503',
    'DIMM_504',
    'DIMM_507',
    'DIMM_509',
    'DIMM_510',
    'DIMM_512',
    'DIMM_518',
    'DIMM_519',
    'DIMM_520',
    'DIMM_523',
    'DIMM_525',
}

DIMMS_TO_IGNORE = {
    'DIMM_11',
}

PATTERN_DISCOVERY_DELAY_LIMIT = 3 * 60 * 60 # 3 hours

def find_file_paths(directory, filename):
    file_paths = []
    for root, _, files in os.walk(directory):
        for file in files:
            if file == filename:
                file_paths.append(os.path.join(root, file))
    return file_paths

def find_sweep_summary_paths(directory):
    file_paths = []
    for root, _, files in os.walk(directory):
        for file in files:
            if file.startswith("sweep-summary") and file.endswith(".json"):
                file_paths.append(os.path.join(root, file))
    return file_paths


################
# Interpret fuzz summary content
################

# Returns True if the check passes, else raises an AssertionError
def check_that_some_bitflip_exists_in_fuzz_summary(fuzz_summary_content):
    # Sanity check: we expect the bit_flips arrays to be all non-empty
    for pattern in fuzz_summary_content["hammering_patterns"]:
        has_bit_flips = False
        for address_mapping in pattern["address_mappings"]:
            assert "bit_flips" in address_mapping, f"Missing bit_flips array in fuzz summary"
            # Check that we have at least a single bit flip per reported pattern
            for bit_flip_descriptor in address_mapping["bit_flips"]:
                for bit_flip_subarray in bit_flip_descriptor:
                    if len(bit_flip_subarray) > 0:
                        has_bit_flips = True
            if has_bit_flips:
                break
        assert has_bit_flips, f"No bit flips in fuzz summary"
    return True

# Returns the number of patterns found in not more than the time limit
def get_num_patterns_found_in_time(start_time, fuzz_summary_content, time_limit):
    num_patterns_discovered_in_time = 0
    for pattern in fuzz_summary_content['hammering_patterns']:
        was_pattern_discovered_in_time = False
        for mapping in pattern['address_mappings']:
            for bit_flip_arr in mapping['bit_flips']:
                for bit_flip in bit_flip_arr:
                    if bit_flip['observed_at'] - start_time < time_limit:
                        num_patterns_discovered_in_time += 1
                        was_pattern_discovered_in_time = True
                        break
                    # if was_pattern_discovered_in_time:
                    #     break
                if was_pattern_discovered_in_time:
                    break
            if was_pattern_discovered_in_time:
                break
    return num_patterns_discovered_in_time

# Returns the number of bit flips found in not more than the time limit.
# @param time_limit: if None, then we do not time-limit. In that case, start_time must be None. Conversely, start_time can be None only if time_limit is None.
def get_num_bit_flips_found_in_time(start_time, fuzz_summary_content, time_limit):
    assert ((start_time, time_limit) == (None, None)) or (start_time is not None and time_limit is not None), f"start_time and time_limit must be either both None or both not None. Found: {start_time}, {time_limit}"
    num_bit_flips_found_in_time = 0
    for pattern in fuzz_summary_content["hammering_patterns"]:
        for address_mapping in pattern["address_mappings"]:
            for bit_flip_descriptor in address_mapping["bit_flips"]:
                for bit_flip_subarray in bit_flip_descriptor:
                    if time_limit is not None and bit_flip_subarray["observed_at"] - start_time > time_limit:
                        continue
                    assert start_time is None or bit_flip_subarray["observed_at"] - start_time >= 0, f"Bit flip observed before start time in fuzz summary"
                    num_bit_flips_found_in_time += bin(bit_flip_subarray["bitmask"]).count("1")
    return num_bit_flips_found_in_time

def get_num_bit_flips_found(fuzz_summary_content):
    return get_num_bit_flips_found_in_time(None, fuzz_summary_content, None)

# Returns the number of bit flips found in not more than the time limit
def get_num_patterns_tested(fuzz_summary_path, start_time, end_time):
    stdout_log_path = fuzz_summary_path.replace("fuzz-summary.json", "stdout.log")
    assert os.path.exists(stdout_log_path), f"Expected to find stdout.log at {stdout_log_path}"
    stdout_log_content = open(stdout_log_path).read()
    # Extract the number of generated patterns from the stdout.log. Even trying without regex from the end of the file is not significantly faster. Files are just super big.
    num_patterns_tested_notscaled = re.findall(r'Number of generated patterns: (\d+)', stdout_log_content)
    assert len(num_patterns_tested_notscaled) == 1, f"Expected to find a single number of generated patterns in `{stdout_log_path}`. Found: {len(num_patterns_tested_notscaled)} occurrences: {num_patterns_tested_notscaled}"
    num_patterns_tested_notscaled = int(num_patterns_tested_notscaled[0])

    return round(num_patterns_tested_notscaled * PATTERN_DISCOVERY_DELAY_LIMIT / (end_time - start_time))

################
# Interpret directory paths
################

def get_num_prefix_dirs(curr_path):
    return str(os.path.split(curr_path)[0])[1:].count(os.path.sep)

def get_directory_parts(curr_path):
    return str(os.path.split(curr_path)[0])[1:].split(os.path.sep)

def get_fenceness_from_directory_part(directory_part: str) -> str:
    fencenesses = re.findall(r'_\w+_[slm]?fence', directory_part)
    assert len(fencenesses) == 1, f"Expected to find a single config in `{directory_part}`. Found: {len(fencenesses)} occurrences: {fencenesses}"
    return fencenesses[0][1:]
def get_timestamp_str_from_directory_part(directory_part: str) -> str:
    assert '_' in directory_part, f"Expected to find a single underscore in `{directory_part}`"
    assert directory_part.startswith('2'), f"Expected to find a timestamp in `{directory_part}`"
    return directory_part.split('_')[0]

def extract_context_from_path(curr_path):
    directory_parts = get_directory_parts(curr_path)
    # Extract the experiment name
    candidate_experiment_names = list(filter(lambda x: x in ('baseline_blacksmith', 'fence_scheduling', 'sweeping-full', 'sweeping'), directory_parts))
    assert len(candidate_experiment_names) == 1, f"Expected to find a single experiment name in `{curr_path}`. Found: {len(candidate_experiment_names)} occurrences: {candidate_experiment_names}"
    experiment_name = candidate_experiment_names[0]
    # Extract the system name
    candidate_system_names = list(filter(lambda x: x in ('ddr4_zen2', 'ddr4_zen3', 'ddr5_zen4', 'ddr4_coffeelake'), directory_parts))
    assert len(candidate_system_names) == 1, f"Expected to find a single system name in `{curr_path}`. Found: {len(candidate_system_names)} occurrences: {candidate_system_names}"
    system_name = candidate_system_names[0]
    # Extract the DIMM ID
    candidate_dimm_names = list(filter(lambda x: x.startswith('DIMM_'), directory_parts))
    assert len(candidate_dimm_names) == 1, f"Expected to find a single DIMM name in `{curr_path}`. Found: {len(candidate_dimm_names)} occurrences: {candidate_dimm_names}"
    dimm_id = candidate_dimm_names[0]
    # Extract the configuration
    if 'coffeelake' in system_name:
        config_name = None
    else:
        candidate_config_names = list(filter(lambda x: x.endswith('_mfence') or x.endswith('_lfence'), directory_parts))
        assert len(candidate_config_names) == 1, f"Expected to find a single config name in `{curr_path}`. Found: {len(candidate_config_names)} occurrences: {candidate_config_names}"
        config_name_dir_part = candidate_config_names[0]
        config_name = get_fenceness_from_directory_part(config_name_dir_part)
    return experiment_name, system_name, dimm_id, config_name

def extract_timestamp_from_path(curr_path):
    directory_parts = get_directory_parts(curr_path)
    # Get the system name just for debug, to check if it's legitimate that we dont see an config
    # Extract the system name
    candidate_system_names = list(filter(lambda x: x in ('ddr4_zen2', 'ddr4_zen3', 'ddr5_zen4', 'ddr4_coffeelake'), directory_parts))
    assert len(candidate_system_names) == 1, f"Expected to find a single system name in `{curr_path}`. Found: {len(candidate_system_names)} occurrences: {candidate_system_names}"
    system_name = candidate_system_names[0]

    if 'coffeelake' in system_name:
        # This will break in 2030
        candidate_config_names = list(filter(lambda x: x.startswith('202') and '_' in x, directory_parts))
    else:
        candidate_config_names = list(filter(lambda x: x.endswith('_mfence') or x.endswith('_lfence'), directory_parts))
    # If we have duplicates, it's ok as long as they have the same first 14 characters. Leave the multiplicity check out for now.
    assert len(candidate_config_names) >= 1, f"Expected to find a single config name in `{curr_path}`. Found: {len(candidate_config_names)} occurrences: {candidate_config_names}"
    config_name_dir_part = candidate_config_names[0]
    return get_timestamp_str_from_directory_part(config_name_dir_part)

# When there are multiple results for the same cpu_type/DIMM/config, we keep the youngest one
def get_forbidden_young_paths(fuzz_summary_paths):
    already_visited_zentype_dimm_config_combinations = defaultdict(lambda: defaultdict(lambda: defaultdict(set)))

    for fuzz_summary_path in fuzz_summary_paths:
        _, cpu_type, dimm_name, fenceness = extract_context_from_path(fuzz_summary_path)
        # Ignore the DDR5 DIMMs
        if dimm_name in DDR5_DIMMS:
            continue
        already_visited_zentype_dimm_config_combinations[cpu_type][dimm_name][fenceness].add(fuzz_summary_path)
    # For each set that has multiple components, find the youngest one
    forbidden_young_paths = set()
    for cpu_type, dimm_config_combinations in already_visited_zentype_dimm_config_combinations.items():
        for dimm_name, config_combinations in dimm_config_combinations.items():
            for fenceness, paths in config_combinations.items():
                if len(paths) > 1:
                    youngest_path = min(paths, key=extract_timestamp_from_path)
                    forbidden_young_paths |= paths - {youngest_path}
    return forbidden_young_paths
